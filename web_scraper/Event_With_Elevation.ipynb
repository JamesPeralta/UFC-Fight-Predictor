{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_html(url):\n",
    "    try_num = 1\n",
    "    response = 0\n",
    "    while(response != 200):\n",
    "        page = requests.get(url)\n",
    "        response = page.status_code\n",
    "        if(response != 200):\n",
    "            if(try_num == 3):\n",
    "                return 'Failed'\n",
    "            else:\n",
    "                try_num += 1\n",
    "                sleep(3)\n",
    "    return page.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "list_ufc_url = 'https://en.wikipedia.org/wiki/List_of_UFC_events'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved elevations: 135\r"
     ]
    }
   ],
   "source": [
    "def get_elevation(url):\n",
    "    page_html = get_page_html(url)\n",
    "    if(page_html == 'Failed'):\n",
    "        return None\n",
    "    parser = BeautifulSoup(page_html, 'html.parser')\n",
    "    tags = parser.select('table.infobox.vcard > tbody > tr')\n",
    "    elevation_str = ''\n",
    "    for tag in tags:\n",
    "        if('elevation' in tag.get_text().lower()):\n",
    "            elevation_str = tag.get_text().lower()\n",
    "            break\n",
    "            \n",
    "    if(elevation_str != ''):\n",
    "        regex = '([\\d]+|[\\d\\,\\d]+|[\\d\\.\\d]+|[\\d\\,]+[\\.\\d]+)(\\sm)'\n",
    "        try:\n",
    "            elevation, elevation_unit = re.search(regex, elevation_str).group().split()\n",
    "            elevation = re.sub(',', '', elevation)\n",
    "            return (elevation + ' ' + elevation_unit).strip()\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def get_column_value(row, col_num, get_url):\n",
    "    try:\n",
    "        if(get_url):\n",
    "            return (row.select('td')[col_num].select('a')[0]['href']).strip()\n",
    "        else:\n",
    "            return (row.select('td')[col_num].get_text()).strip()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_past_events(url):\n",
    "    page_html = get_page_html(url)\n",
    "    parser = BeautifulSoup(page_html, 'html.parser')\n",
    "    \n",
    "    past_event_table = parser.select('table#Past_events.sortable.wikitable')[0]\n",
    "    table_rows = past_event_table.select('tbody > tr')\n",
    "    \n",
    "    event_urls = []\n",
    "    venue_elevations = dict()\n",
    "    count = 0\n",
    "    \n",
    "    for index in range(1, len(table_rows)):\n",
    "        row = table_rows[index]\n",
    "        # if the event was cancelled, skip\n",
    "        if(get_column_value(row, 5, False) == 'Cancelled'):\n",
    "            continue\n",
    "\n",
    "        event_url = get_column_value(row, 1, True)\n",
    "        if(event_url != None):\n",
    "            event_urls.append(event_url)\n",
    "        \n",
    "        location = get_column_value(row, 4, False)\n",
    "        location = re.sub('U\\.S\\.', 'USA', location)\n",
    "        location = re.sub('U\\.K\\.', 'United Kingdom', location)    \n",
    "        location_url = get_column_value(row, 4, True)\n",
    "        \n",
    "        if(location not in venue_elevations):            \n",
    "            location_elevation = get_elevation('https://en.wikipedia.org' + location_url)\n",
    "            if(location_elevation != None):\n",
    "                count += 1\n",
    "                venue_elevations[location] = location_elevation\n",
    "                print('Retrieved elevations: {:3d}'.format(count), end='\\r', flush=True)\n",
    "\n",
    "    return venue_elevations, event_urls\n",
    "\n",
    "elevations_data, event_urls = get_past_events(list_ufc_url)\n",
    "elevations_df = pd.DataFrame.from_dict(elevations_data, columns=['location_elevation'], orient='index')\n",
    "elevations_df.rename_axis('location', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_elevation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>São Paulo, Brazil</td>\n",
       "      <td>760 m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>New York City, New York, USA</td>\n",
       "      <td>10 m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Boston, Massachusetts, USA</td>\n",
       "      <td>43 m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tampa, Florida, USA</td>\n",
       "      <td>14.6 m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>31 m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             location_elevation\n",
       "location                                       \n",
       "São Paulo, Brazil                         760 m\n",
       "New York City, New York, USA               10 m\n",
       "Boston, Massachusetts, USA                 43 m\n",
       "Tampa, Florida, USA                      14.6 m\n",
       "Melbourne, Australia                       31 m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elevations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_elevations = {\n",
    "    'Saint Petersburg, Russia' : '175.9 m',\n",
    "    'Adelaide, Australia': '727 m',\n",
    "    'Sydney, Australia': '130 m',\n",
    "    'Saitama, Japan': '20 m',\n",
    "    'Dublin, Ireland': '85 m',\n",
    "    'Uncasville, Connecticut, USA': '335 m',\n",
    "    'Rosemont, Illinois, USA': '194.8 m',\n",
    "    'Brisbane, Australia': '27 m',\n",
    "    'Fort Hood, Texas, USA': '219 m',\n",
    "    'Belfast, Northern Ireland, United Kingdom': '80 m',\n",
    "    'Newcastle, England, United Kingdom': '56 m',\n",
    "    'Gold Coast, Australia': '16 m',\n",
    "    'Perth, Australia': '15 m',\n",
    "    'Glasgow, Scotland, United Kingdom': '6 m',\n",
    "    'Hamburg, Germany': '116.2 m',\n",
    "    'Fort Campbell, Kentucky, USA': '168 m',\n",
    "    'Moscow, Russia': '156 m',\n",
    "    'Marina Bay, Singapore': '0 m',\n",
    "    'Manila, Philippines': '12 m',\n",
    "    'Mashantucket, Connecticut, USA': '90 m',\n",
    "    'Chiba, Japan': '0 m',\n",
    "    'Kallang, Singapore': '15 m',\n",
    "    'Yokohama, Japan': '43 m',\n",
    "    'Summerlin, Nevada, USA': '822 m',\n",
    "    'Brooklyn, New York, USA': '66 m',\n",
    "    'Killeen, Texas, USA': '270 m',\n",
    "    'Ledyard, Connecticut, USA': '90 m',\n",
    "    'San Juan, Puerto Rico': '8 m'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding missing locations\n",
    "for location, elevation in missing_elevations.items():\n",
    "    elevations_df.loc[location] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating csv\n",
    "elevations_df.to_csv('locations_elevation_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in event_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_fighter_url(cols, col_num):\n",
    "    try:\n",
    "        return cols[col_num].text.strip(), cols[col_num].find('a')['href'].strip()\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def extract_fighter_urls(urls):\n",
    "    fighter_urls = dict()\n",
    "    fighter_url_count = 0\n",
    "    event_count = 0\n",
    "    total_events = len(urls)\n",
    "    \n",
    "    for url in urls:\n",
    "        event_count += 1\n",
    "        page_html = get_page_html('https://en.wikipedia.org' + url)\n",
    "        if(page_html == 'Failed'):\n",
    "            continue\n",
    "        parser = BeautifulSoup(page_html, 'html.parser')\n",
    "        fight_rows = parser.find('table', {'class': 'toccolours'}).findAll('tr')\n",
    "    \n",
    "        for fight in fight_rows:\n",
    "            if fight.find('th') is None:\n",
    "                cols = fight.findAll('td')\n",
    "            \n",
    "                fighter1_name, fighter1_url  = get_fighter_url(cols, 1)\n",
    "                fighter2_name, fighter2_url = get_fighter_url(cols, 3)\n",
    "            \n",
    "                if((fighter1_name != None and fighter1_url != None) and (fighter1_name not in fighter_urls)):\n",
    "                    fighter_urls[fighter1_name] = fighter1_url\n",
    "                    fighter_url_count += 1\n",
    "                    print('Event: {:3d} of {}. Retrieved urls: {:3d}'.format(event_count, total_events, fighter_url_count), end='\\r', flush=True)\n",
    "\n",
    "                if((fighter2_name != None and fighter2_url != None) and (fighter2_name not in fighter_urls)):\n",
    "                    fighter_urls[fighter2_name] = fighter2_url\n",
    "                    fighter_url_count += 1\n",
    "                    print('Event: {:3d} of {}. Retrieved urls: {:3d}'.format(event_count, total_events, fighter_url_count), end='\\r', flush=True)\n",
    "    return fighter_urls\n",
    "                    \n",
    "fighter_urls = extract_fighter_urls(event_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_location(table_rows, fighter_name):\n",
    "    location_url = None\n",
    "    location = None\n",
    "    \n",
    "    fighting_out_of = table_rows.find('th', string='Fighting out of')\n",
    "    if(fighting_out_of != None):\n",
    "        element = fighting_out_of.find_parent().select('td')[0].find('a')\n",
    "        if(element == None):\n",
    "            element = fighting_out_of.find_parent().select('td')[0]\n",
    "        location = ''\n",
    "        while(True):\n",
    "            if((element == None) or (element.name != None and element.name == 'br')):\n",
    "                break\n",
    "            try:\n",
    "                location += element.get_text()\n",
    "            except:\n",
    "                location += element\n",
    "            element = element.next_sibling            \n",
    "        try:\n",
    "            location = re.search('([^\\[]+).*', location).group(1)\n",
    "            location_url = fighting_out_of.find_parent().select('td > a')[0]['href']\n",
    "            return location, location_url\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    residence = table_rows.find('th', string='Residence')\n",
    "    if(residence == None):\n",
    "        residence = table_rows.find('th', string='Residence:')\n",
    "    if(residence != None):\n",
    "        try:\n",
    "            location = residence.find_parent().select('td')[0].get_text().strip()\n",
    "            location_url = residence.find_parent().select('td > a')[0]['href']\n",
    "            return location, location_url\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    born = table_rows.find('th', string='Born:')\n",
    "    if(born == None):\n",
    "        born = table_rows.find('th', string='Born')\n",
    "    if(born != None):\n",
    "        try:\n",
    "            regex = '.*[\\)|\\]]([^\\[]+)'\n",
    "            location = re.search(regex, born.find_parent().select('td')[0].get_text().strip()).group(1)\n",
    "            location_url = born.find_parent().select('td > a')[0]['href']\n",
    "            return location, location_url\n",
    "        except:\n",
    "            pass\n",
    "    return location, location_url\n",
    "\n",
    "def get_fighters_location(fighters):\n",
    "    print('Total number of fighters:', len(fighters))\n",
    "    \n",
    "    count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    data = pd.DataFrame(columns=['Fighter Name', 'Location', 'Elevation'])\n",
    "    data.set_index('Fighter Name', inplace=True)\n",
    "    \n",
    "    for fighter_name, fighter_url in fighters.items():\n",
    "        page_html = get_page_html('https://en.wikipedia.org' + fighter_url)\n",
    "        if(page_html == 'Failed'):\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        parser = BeautifulSoup(page_html, 'html.parser')\n",
    "        try:\n",
    "            table_rows = parser.select('table.infobox.vcard > tbody')[0]\n",
    "        except:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        location, location_url = get_location(table_rows, fighter_name)\n",
    "        \n",
    "        if(location == None or location_url == None):\n",
    "            count += 1\n",
    "            continue    \n",
    "        location = re.sub('U\\.S\\.', 'USA', location)\n",
    "        location = re.sub('U\\.K\\.', 'United Kingdom', location)    \n",
    "\n",
    "        if(location_url != None):\n",
    "            elevation = get_elevation('https://en.wikipedia.org' + location_url)\n",
    "            if(elevation != None):\n",
    "                data.loc[fighter_name] = [location, elevation]                \n",
    "                count += 1\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "        else:\n",
    "            skipped_count += 1\n",
    "        \n",
    "        print('Fighter locations retrieved: {:4d}, skipped: {:3d}'.format(count, skipped_count), end='\\r', flush=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "fighter_locations_df = get_fighters_location(fighter_urls)\n",
    "fighter_locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating csv\n",
    "fighter_locations_df.to_csv('fighters_elevation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
