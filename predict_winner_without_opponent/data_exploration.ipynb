{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Fight Data and Merge with Hometown Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fight Data Stats: \n",
      "Shape:  (5144, 141)\n",
      "\n",
      "Blue fighter Stats: \n",
      "Shape:  (5144, 72)\n",
      "\n",
      "Red fighter Stats: \n",
      "Shape:  (5144, 72)\n",
      "\n",
      "Total fighter Stats: \n",
      "Shape:  (10288, 72)\n",
      "\n",
      "Fighters no offensive stats: \n",
      "Shape:  (10288, 23)\n",
      "\n",
      "Hometown Stats: \n",
      "Shape:  (1331, 4)\n",
      "\n",
      "Fighter + offensive + hometown data stats: \n",
      "Shape:  (10288, 74)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fight_data_file = '../ufcdata/data.csv'\n",
    "fight_data_file_prep = '../ufcdata/preprocessed_data.csv'\n",
    "scorecard_data_file = '../scorecard/scorecard.csv'\n",
    "hometown_data_file = '../elevations/fighters_elevation.csv'\n",
    "\n",
    "def import_and_merge():\n",
    "    fight_data = pd.read_csv(fight_data_file)\n",
    "    hometown_data = pd.read_csv(hometown_data_file)\n",
    "    \n",
    "    #Add Blue and Red win columns\n",
    "    fight_data['B_Winner'] = [1 if x=='Blue' else 0 for x in fight_data['Winner']]\n",
    "    fight_data['R_Winner'] = [1 if x=='Red' else 0 for x in fight_data['Winner']]\n",
    "    \n",
    "    #Drop columns irrelevant to this prediction\n",
    "    fight_data = fight_data.drop(columns=['Referee', 'no_of_rounds', 'Winner', 'date', 'R_Stance', 'B_Stance'])\n",
    "    print('Fight Data Stats: ')\n",
    "    print('Shape: ', fight_data.shape)\n",
    "    #display(fight_data)\n",
    "    \n",
    "    #Separate fight data into individual fighter stats\n",
    "    blue_fighters = fight_data.loc[:, [col for col in fight_data.columns if re.search('^R_', col)==None]]\n",
    "    blue_fighters = blue_fighters.rename(columns=lambda x: re.sub('^B_', '', x))\n",
    "    print('\\nBlue fighter Stats: ')\n",
    "    print('Shape: ', blue_fighters.shape)\n",
    "    #display(blue_fighters)\n",
    "    \n",
    "    red_fighters = fight_data.loc[:, [col for col in fight_data.columns if re.search('^B_', col)==None]]\n",
    "    red_fighters = red_fighters.rename(columns=lambda x: re.sub('^R_', '', x))\n",
    "    print('\\nRed fighter Stats: ')\n",
    "    print('Shape: ', red_fighters.shape)\n",
    "    #display(red_fighters)\n",
    "    \n",
    "    #Concatenate blue and red fighter stats\n",
    "    fighters_data = pd.concat([blue_fighters, red_fighters])\n",
    "    fighters_data = fighters_data.rename(columns={'total_time_fought(seconds)':'total_time_fought_seconds'})\n",
    "    print('\\nTotal fighter Stats: ')\n",
    "    print('Shape: ', fighters_data.shape)\n",
    "    \n",
    "    # Create df without offence stats\n",
    "    fighters_no_offence_stats = fighters_data.drop(columns=[col for col in fighters_data.columns if re.search('^avg_', col) != None])\n",
    "    fighters_no_offence_stats = fighters_no_offence_stats.drop(columns='total_time_fought_seconds')\n",
    "    print('\\nFighters no offensive stats: ')\n",
    "    print('Shape: ', fighters_no_offence_stats.shape)\n",
    "    \n",
    "    #Merge with home town data\n",
    "    hometown_data['merge_key'] = hometown_data['Fighter Name'].apply(lambda x: ' '.join(sorted(str.lower(x).split())))\n",
    "    hometown_data = hometown_data[~hometown_data.duplicated('merge_key', keep='first')]\n",
    "    print('\\nHometown Stats: ')\n",
    "    print('Shape: ', hometown_data.shape)\n",
    "    \n",
    "    merged_df = fighters_data.copy()\n",
    "    merged_df['merge_key'] = merged_df['fighter'].apply(lambda x: ' '.join(sorted(str.lower(x).split())))\n",
    "    merged_df = pd.merge(left=merged_df, right=hometown_data, how='left', left_on='merge_key', right_on='merge_key')\n",
    "    merged_df = merged_df.drop(columns=['Fighter Name', 'merge_key'])\n",
    "    merged_df = merged_df.rename(columns={'Location':'hometown'})\n",
    "    print('\\nFighter + offensive + hometown data stats: ')\n",
    "    print('Shape: ', merged_df.shape)\n",
    "    #display(merged_df)\n",
    "\n",
    "    \n",
    "    return (fighters_no_offence_stats, fighters_data, merged_df)\n",
    "    \n",
    "data_no_offence_stats, data, data_w_hometown,  = import_and_merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Selection\n",
    "- Separate location and home town into city and country\n",
    "- Categorize weight_class, title_bout, Stance, and locations\n",
    "- Convert elevation data into numeric data\n",
    "- Tune parameters\n",
    "- Visualize model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def plot_missing_vals(df):\n",
    "    columns = []\n",
    "    nans_per_col = []\n",
    "    \n",
    "\n",
    "    for col in df.columns:\n",
    "        num_nans = sum(pd.isnull(df[col]))\n",
    "        #print('Num of NaNs in col ', col, ': ', num_nans)\n",
    "        columns.append(col)\n",
    "        nans_per_col.append(num_nans)\n",
    "    \n",
    "    print('Shape: ', df.shape)\n",
    "    fig = plt.figure(figsize=(30, 13))\n",
    "    ax = plt.axes()\n",
    "    ax.bar(columns, nans_per_col)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.ylabel('# NaNs')\n",
    "    plt.title('Number of missing data per feature')\n",
    "    \n",
    "def inspect_data(fighter_df):\n",
    "    # Display missing value numbers in fighter data\n",
    "    print('\\nBefore dropping fightres with no offence/defence stats')\n",
    "    #plot_missing_vals(fighter_df)\n",
    "        \n",
    "    #Remove rows with a lot of missing information\n",
    "    if 'avg_BODY_att' in fighter_df.columns:\n",
    "        fighter_df = fighter_df[~pd.isnull(fighter_df['avg_BODY_att'])]\n",
    "    elif 'total_time_fought_seconds' in fighter_df.columns:\n",
    "        fighter_df = fighter_df[~pd.isnull(fighter_df['total_time_fought_seconds'])]       \n",
    "    print('\\nAfter dropping fighters with no offence/defemce stats') \n",
    "    #plot_missing_vals(fighter_df)\n",
    "    \n",
    "    #Fighter age, weight, height, and reach distribution\n",
    "    hrw_attrs_df = pd.DataFrame(fighter_df[['Height_cms', 'Reach_cms', 'Weight_lbs']])    \n",
    "    fig = plt.figure(figsize=(30, 13))\n",
    "    ax = plt.axes()\n",
    "    hrw_attrs_df.boxplot()\n",
    "    plt.title('Height, Reach and weight dsitributions')\n",
    "    plt.ylim([100, 250])\n",
    "    \n",
    "    age_df = pd.DataFrame(fighter_df[['age']])   \n",
    "    fig = plt.figure(figsize=(30, 13))\n",
    "    ax = plt.axes()\n",
    "    age_df.boxplot()\n",
    "    plt.title('Age dsitributions')\n",
    "       \n",
    "\n",
    "def clean_data(fighter_df):    \n",
    "   #Fill missing values for height, reach, weight, age\n",
    "    weight_class_means = {}\n",
    "    weight_classes = np.unique(fighter_df['weight_class'])\n",
    "    for weight_class in weight_classes:\n",
    "        weight_class_idx = fighter_df['weight_class'] == weight_class\n",
    "        \n",
    "        null_idx = np.logical_and(pd.isnull(fighter_df['Height_cms']), weight_class_idx)\n",
    "        fighter_df.loc[null_idx, 'Height_cms'] = np.nanmean(fighter_df.loc[weight_class_idx, 'Height_cms'])\n",
    "        \n",
    "        null_idx = np.logical_and(pd.isnull(fighter_df['Reach_cms']), weight_class_idx)\n",
    "        fighter_df.loc[null_idx, 'Reach_cms'] = np.nanmean(fighter_df.loc[weight_class_idx, 'Reach_cms'])\n",
    "        \n",
    "        null_idx = np.logical_and(pd.isnull(fighter_df['Weight_lbs']), weight_class_idx)\n",
    "        fighter_df.loc[null_idx, 'Weight_lbs'] = np.nanmean(fighter_df.loc[weight_class_idx, 'Weight_lbs'])\n",
    "        \n",
    "        null_idx = np.logical_and(pd.isnull(fighter_df['age']), weight_class_idx)\n",
    "        fighter_df.loc[null_idx, 'age'] = np.nanmean(fighter_df.loc[weight_class_idx, 'age'])\n",
    "    \n",
    "    # Replacet title bout with actual numbers\n",
    "    fighter_df.loc[fighter_df['title_bout'] == 'True', 'title_bout'] = 1\n",
    "    fighter_df.loc[fighter_df['title_bout'] == 'False', 'title_bout'] = 0\n",
    "    \n",
    "    #Drop rows with too many missing values\n",
    "    if 'avg_BODY_att' in fighter_df.columns:\n",
    "        fighter_df = fighter_df.loc[~pd.isnull(fighter_df['avg_BODY_att']), :]    \n",
    "        \n",
    "    return fighter_df\n",
    "\n",
    "def structure_data(fighter_df):   \n",
    "    # Split Locations  and hometowns into city and country\n",
    "    if 'location' in fighter_df.columns:\n",
    "        fighter_df['city'] = [str.lower(location.split(', ')[0]) for location in fighter_df['location']]\n",
    "        fighter_df['country'] = [str.lower(location.split(', ')[-1]) for location in fighter_df['location']]\n",
    "        fighter_df = fighter_df.drop(columns='location')\n",
    "    \n",
    "    if 'hometown' in fighter_df.columns:\n",
    "        #First get rid of data with nan hometowns\n",
    "        fighter_df['hometown_city'] = [str.lower(location.split(', ')[0]) for location in fighter_df['hometown']]\n",
    "        fighter_df['hometown_country'] = [str.lower(location.split(', ')[-1]) for location in fighter_df['hometown']]\n",
    "        fighter_df.drop(columns='hometown')\n",
    "        \n",
    "    return fighter_df\n",
    "    \n",
    "\n",
    "def compare_models(knn_params, lr_params, svc_params, nbayes_params, rforest_params, features, labels): # Receives already scales\n",
    "    accuracy_df = pd.DataFrame(columns=['KNN', 'Logistic Regression', 'SVC', 'Naive Bayes', 'Random Forest'])\n",
    "    precision_df = pd.DataFrame(columns=['KNN', 'Logistic Regression', 'SVC', 'Naive Bayes', 'Random Forest'])\n",
    "    recall_df = pd.DataFrame(columns=['KNN', 'Logistic Regression', 'SVC', 'Naive Bayes', 'Random Forest'])\n",
    "    f1_df = pd.DataFrame(columns=['KNN', 'Logistic Regression', 'SVC', 'Naive Bayes', 'Random Forest'])\n",
    "    \n",
    "    idx = 0;\n",
    "    for seed in range(1, 20):\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(features, labels, train_size=0.75, test_size=0.25, random_state=seed, stratify=labels)\n",
    "        \n",
    "        #Models\n",
    "        knn = KNeighborsClassifier(**knn_params).fit(X_train_scaled, y_train)    \n",
    "        lr = LogisticRegression(**lr_params).fit(X_train_scaled, y_train)  \n",
    "        svc = LinearSVC(**svc_params).fit(X_train_scaled, y_train)\n",
    "        n_bayes = BernoulliNB(**nbayes_params).fit(X_train_scaled, y_train)\n",
    "        random_forest = RandomForestClassifier(n_estimators=50, **rforest_params).fit(X_train_scaled, y_train)\n",
    "        \n",
    "        #Update tables\n",
    "        accuracy_df.loc[idx] = [knn.score(X_test_scaled, y_test), lr.score(X_test_scaled, y_test), svc.score(X_test_scaled, y_test), \n",
    "                                n_bayes.score(X_test_scaled, y_test), random_forest.score(X_test_scaled, y_test)]\n",
    "\n",
    "        precision_df.loc[idx] = [precision_score(y_test, knn.predict(X_test_scaled)), precision_score(y_test, lr.predict(X_test_scaled)), \n",
    "                                 precision_score(y_test, svc.predict(X_test_scaled)), precision_score(y_test, n_bayes.predict(X_test_scaled)),\n",
    "                                 precision_score(y_test, random_forest.predict(X_test_scaled))]\n",
    "\n",
    "        recall_df.loc[idx] = [recall_score(y_test, knn.predict(X_test_scaled)), recall_score(y_test, lr.predict(X_test_scaled)), \n",
    "                              recall_score(y_test, svc.predict(X_test_scaled)), recall_score(y_test, n_bayes.predict(X_test_scaled)),\n",
    "                              recall_score(y_test, random_forest.predict(X_test_scaled))]\n",
    "\n",
    "        f1_df.loc[idx] = [f1_score(y_test, knn.predict(X_test_scaled)), f1_score(y_test, lr.predict(X_test_scaled)), \n",
    "                          f1_score(y_test, svc.predict(X_test_scaled)), f1_score(y_test, n_bayes.predict(X_test_scaled)),\n",
    "                          f1_score(y_test, random_forest.predict(X_test_scaled))]\n",
    "        idx += 1\n",
    "        \n",
    "    #Display results\n",
    "    display('\\nMedian accuracy score:', accuracy_df.median())\n",
    "    display('\\nMedian precision score:', precision_df.median())\n",
    "    display('\\nMedian recall score:', recall_df.median())\n",
    "    display('\\nMedian F1 score:', f1_df.median())\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    accuracy_df.boxplot()\n",
    "    plt.title('Accuracy scores')\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 7))       \n",
    "    precision_df.boxplot()\n",
    "    plt.title('Precision score')\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 7))        \n",
    "    recall_df.boxplot()\n",
    "    plt.title('Recall score')\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 7))        \n",
    "    f1_df.boxplot()\n",
    "    plt.title('F1 score')\n",
    "    \n",
    "    \n",
    "def parameter_tuning(df, scale):\n",
    "    #inspect_data(df.copy())\n",
    "    df = structure_data(df)\n",
    "    df = clean_data(df)\n",
    "    df = df.drop(columns=['fighter'])\n",
    "    dummy_df = pd.get_dummies(df)\n",
    "    \n",
    "    labels = dummy_df['Winner']\n",
    "    features = dummy_df.drop(columns=['Winner'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.75, test_size=0.25, random_state=0, stratify=labels)\n",
    "    \n",
    "    #Scale\n",
    "    if scale:\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled = X_train\n",
    "        X_test_scaled = X_test\n",
    "\n",
    "    \n",
    "    # Search for best parameters\n",
    "    knn = KNeighborsClassifier().fit(X_train_scaled, y_train)\n",
    "    knn_tuner = GridSearchCV(knn, param_grid={'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'n_neighbors':list(range(1,51))}).fit(X_train_scaled, y_train)\n",
    "    print('KNN Best params:', knn_tuner.best_params_ )\n",
    "    \n",
    "    lr = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "    lr_tuner =  GridSearchCV(lr, param_grid={'solver':['newton-cg', 'lbfgs', 'liblinear'], 'C':list(np.linspace(0.001,20,40))}).fit(X_train_scaled, y_train)\n",
    "    print('LR Best params:', lr_tuner.best_params_)\n",
    "    \n",
    "    svc = LinearSVC().fit(X_train_scaled, y_train)\n",
    "    svc_tuner = GridSearchCV(svc, param_grid={'C':list(np.linspace(0.0000000001, 0.15, 50))}).fit(X_train_scaled, y_train)\n",
    "    print('SVC Best params:', svc_tuner.best_params_)\n",
    "    \n",
    "    n_bayes = BernoulliNB().fit(X_train_scaled, y_train)\n",
    "    nbayes_tuner = GridSearchCV(n_bayes, param_grid={'alpha':list(np.linspace(0.0000000001, 21, 50))}).fit(X_train_scaled, y_train)\n",
    "    print('NaiveBayes Best params:', nbayes_tuner.best_params_)\n",
    "    \n",
    "    random_forest = RandomForestClassifier(n_estimators=100, random_state=0).fit(X_train_scaled, y_train)\n",
    "    rforest_tuner = GridSearchCV(random_forest, param_grid={'max_features':['auto', 'sqrt', 'log2'], 'max_depth':list(np.linspace(1,30,50)), 'min_samples_split':list(range(2,30))}).fit(X_train_scaled, y_train)\n",
    "    print('RandomForest Best params:', rforest_tuner.best_params_)\n",
    "    \n",
    "    # Compare models with tuned parameters\n",
    "    compare_models( knn_tuner.best_params_, lr_tuner.best_params_, svc_tuner.best_params_, nbayes_tuner.best_params_, rforest_tuner.best_params_, features, labels)\n",
    "    return(knn_tuner.best_params_, lr_tuner.best_params_, svc_tuner.best_params_, nbayes_tuner.best_params_, rforest_tuner.best_params_, features, labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models for Data with no offensive stats\n",
    "knn_params, lr_params, svc_params, nbayes_params, rforest_params, features, labels = parameter_tuning(data_no_offence_stats, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Best params: {'algorithm': 'auto', 'n_neighbors': 15}\n",
      "LR Best params: {'C': 0.001, 'solver': 'liblinear'}\n",
      "SVC Best params: {'C': 0.05204081639183673}\n",
      "NaiveBayes Best params: {'alpha': 14.571428571459185}\n"
     ]
    }
   ],
   "source": [
    "# Compare models for data with offensive stats\n",
    "knn_params_offence, lr_params_offence, svc_params_offence, nbayes_params_offence, rforest_params_offence, features_offence, labels_offence = parameter_tuning(data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned Parameters for unsclaed data. Data with no offensive stats\n",
    "def evaluate_models_best_params_no_offence(data):\n",
    "    knn_params =  {'algorithm': 'auto', 'n_neighbors': 19}\n",
    "    lr_params = {'C': 0.001, 'solver': 'newton-cg'}\n",
    "    svc_params = {'C': 0.11326530614693876}\n",
    "    nbayes_params =  {'alpha': 12.428571428612246}\n",
    "    rforest_params = {'max_depth': 7.5102040816326525, 'max_features': 'auto', 'min_samples_split': 4}\n",
    "    df = structure_data(data_no_offence_stats.copy())\n",
    "    df = clean_data(df)\n",
    "    df = df.drop(columns=['fighter'])\n",
    "    dummy_df = pd.get_dummies(df)\n",
    "\n",
    "    labels = dummy_df['Winner']\n",
    "    features = dummy_df.drop(columns=['Winner'])\n",
    "    compare_models(knn_params, lr_params, svc_params, nbayes_params, rforest_params, features, labels)\n",
    "\n",
    "#Parameters for data with offence stats\n",
    "def evaluate_models_best_params(data):\n",
    "    knn_params = {'algorithm': 'auto', 'n_neighbors': 15}\n",
    "    lr_params = {'C': 0.001, 'solver': 'liblinear'}\n",
    "    svc_params = {'C': 0.05204081639183673}\n",
    "    nbayes_params = {'alpha': 14.571428571459185}\n",
    "    rforest_params = {'max_depth': 10.46938775510204, 'max_features': 'auto', 'min_samples_split': 18}\n",
    "    df = structure_data(data.copy())\n",
    "    df = clean_data(df)\n",
    "    df = df.drop(columns=['fighter'])\n",
    "    dummy_df = pd.get_dummies(df)\n",
    "\n",
    "    labels = dummy_df['Winner']\n",
    "    features = dummy_df.drop(columns=['Winner'])\n",
    "    compare_models(knn_params, lr_params, svc_params, nbayes_params, rforest_params, features, labels)\n",
    "    \n",
    "#Second pair of parameters\n",
    "# knn_params = {'algorithm': 'auto', 'n_neighbors': 49}\n",
    "# lr_params = {'C': 9.23130769230769, 'solver': 'lbfgs'}\n",
    "# svc_params = {'C': 0.003061224587755102}\n",
    "# nbayes_params = {'alpha': 18.000000000014285}\n",
    "# rforest_params = {'max_depth': 10.46938775510204, 'max_features': 'auto', 'min_samples_split': 18}\n",
    "# df = structure_data(data_no_offence_stats.copy())\n",
    "# df = clean_data(df)\n",
    "# df = df.drop(columns=['fighter'])\n",
    "# dummy_df = pd.get_dummies(df)\n",
    "\n",
    "# labels = dummy_df['Winner']\n",
    "# features = dummy_df.drop(columns=['Winner'])\n",
    "# compare_models(knn_params, lr_params, svc_params, nbayes_params, rforest_params, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****ALL FEATURES********\n",
      "\n",
      "No offence stats\n",
      "KNN, LogisticR, SVC, NB, RandomF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Median accuracy score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.529549\n",
       "Logistic Regression    0.550933\n",
       "SVC                    0.508165\n",
       "Naive Bayes            0.516330\n",
       "Random Forest          0.540824\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median precision score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.520408\n",
       "Logistic Regression    0.547535\n",
       "SVC                    0.491835\n",
       "Naive Bayes            0.506446\n",
       "Random Forest          0.538124\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median recall score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.524111\n",
       "Logistic Regression    0.491700\n",
       "SVC                    0.007115\n",
       "Naive Bayes            0.656917\n",
       "Random Forest          0.471146\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median F1 score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.525903\n",
       "Logistic Regression    0.517471\n",
       "SVC                    0.014073\n",
       "Naive Bayes            0.571624\n",
       "Random Forest          0.503129\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Offence stats\n",
      "KNN, LogisticR, SVC, NB, RandomF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Median accuracy score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.515759\n",
       "Logistic Regression    0.571156\n",
       "SVC                    0.505253\n",
       "Naive Bayes            0.508118\n",
       "Random Forest          0.546323\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median precision score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.519658\n",
       "Logistic Regression    0.574586\n",
       "SVC                    0.514460\n",
       "Naive Bayes            0.511203\n",
       "Random Forest          0.550459\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median recall score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.544423\n",
       "Logistic Regression    0.581285\n",
       "SVC                    0.201323\n",
       "Naive Bayes            0.621928\n",
       "Random Forest          0.562382\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Median F1 score:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KNN                    0.531494\n",
       "Logistic Regression    0.579615\n",
       "SVC                    0.297486\n",
       "Naive Bayes            0.563597\n",
       "Random Forest          0.553231\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****TOP CORRELATED FEATURES ONLY********\n",
      "\n",
      "No offence stats\n"
     ]
    }
   ],
   "source": [
    "# Explore correlation and find best correlated features\n",
    "def plot_correlation(data_no_offence_stats):\n",
    "    df = clean_data(data_no_offence_stats.copy())\n",
    "    df = df.drop(columns=['fighter','location', 'weight_class'])\n",
    "    dummy_df = pd.get_dummies(df)\n",
    "\n",
    "    corr = dummy_df.corr()['Winner'][:]\n",
    "    corr = corr.drop(['Winner']) * 100\n",
    "    corr = corr.loc[~pd.isnull(corr)]\n",
    "    corr = abs(corr).sort_values()\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 13))\n",
    "    ax = plt.axes()\n",
    "    ax.bar(corr.index, corr)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.ylabel('Correlation')\n",
    "    \n",
    "    most_corr_features = corr.index[-int(len(corr)/2):]\n",
    "    return most_corr_features\n",
    "\n",
    "most_corr_features_no_offence = plot_correlation(data_no_offence_stats)\n",
    "most_corr_features = plot_correlation(data)\n",
    "\n",
    "# See if models improve with most correlated features\n",
    "print('*****ALL FEATURES********')\n",
    "print('\\nNo offence stats')\n",
    "evaluate_models_best_params_no_offence(data_no_offence_stats.copy())\n",
    "print('\\n\\nOffence stats')\n",
    "evaluate_models_best_params(data.copy())\n",
    "\n",
    "print('*****TOP CORRELATED FEATURES ONLY********')\n",
    "print('\\nNo offence stats')\n",
    "evaluate_models_best_params_no_offence(data_no_offence_stats[most_corr_features_no_offence].copy())\n",
    "print('\\n\\nOffence stats')\n",
    "evaluate_models_best_params(data[most_corr_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if models improve with best parameters\n",
    "data_no_offence_stats.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seek to improve logistic Regression with feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
