{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Model imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.activations import relu, sigmoid\n",
    "\n",
    "import talos as ta\n",
    "from talos.model.normalizers import lr_normalizer\n",
    "from talos.model.hidden_layers import hidden_layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the performance of a DNN on preprocessed_ratio_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_data_location = '../generated_data/combined_fight_data.csv'\n",
    "\n",
    "ufc_data = pd.read_csv(ufc_data_location)\n",
    "ufc_data.drop(columns=['date', 'R_fighter', 'B_fighter', 'Referee', 'city', 'country', 'end_how'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>title_bout</th>\n",
       "      <th>weight_class</th>\n",
       "      <th>no_of_rounds</th>\n",
       "      <th>B_current_lose_streak</th>\n",
       "      <th>B_current_win_streak</th>\n",
       "      <th>B_draw</th>\n",
       "      <th>B_avg_BODY_att</th>\n",
       "      <th>B_avg_BODY_landed</th>\n",
       "      <th>B_avg_CLINCH_att</th>\n",
       "      <th>...</th>\n",
       "      <th>R_Reach_cms</th>\n",
       "      <th>R_Weight_lbs</th>\n",
       "      <th>B_age</th>\n",
       "      <th>R_age</th>\n",
       "      <th>location_elevation</th>\n",
       "      <th>end_method</th>\n",
       "      <th>end_round</th>\n",
       "      <th>attendance</th>\n",
       "      <th>R_home_elevation</th>\n",
       "      <th>B_home_elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>Open Weight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1734.00</td>\n",
       "      <td>tko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>Open Weight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1734.00</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>13730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>Open Weight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1734.00</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>Catch Weight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1734.00</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>Open Weight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1734.00</td>\n",
       "      <td>tko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5057</td>\n",
       "      <td>Red</td>\n",
       "      <td>True</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>162.56</td>\n",
       "      <td>135.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>182.02</td>\n",
       "      <td>tko</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16083.0</td>\n",
       "      <td>3310.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5058</td>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>Heavyweight</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>190.50</td>\n",
       "      <td>264.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>182.02</td>\n",
       "      <td>decision</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5059</td>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>175.26</td>\n",
       "      <td>135.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>182.02</td>\n",
       "      <td>ko</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16083.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5060</td>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>Featherweight</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>...</td>\n",
       "      <td>180.34</td>\n",
       "      <td>145.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>182.02</td>\n",
       "      <td>ko</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16083.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5061</td>\n",
       "      <td>Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>Bantamweight</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.75</td>\n",
       "      <td>...</td>\n",
       "      <td>172.72</td>\n",
       "      <td>135.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>182.02</td>\n",
       "      <td>decision</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16083.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5062 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Winner  title_bout   weight_class  no_of_rounds  B_current_lose_streak  \\\n",
       "0       Red       False    Open Weight             1                    0.0   \n",
       "1       Red       False    Open Weight             1                    0.0   \n",
       "2       Red       False    Open Weight             1                    0.0   \n",
       "3       Red        True   Catch Weight             1                    0.0   \n",
       "4       Red       False    Open Weight             1                    0.0   \n",
       "...     ...         ...            ...           ...                    ...   \n",
       "5057    Red        True   Bantamweight             5                    0.0   \n",
       "5058   Blue       False    Heavyweight             3                    0.0   \n",
       "5059    Red       False   Bantamweight             3                    0.0   \n",
       "5060   Blue       False  Featherweight             3                    0.0   \n",
       "5061   Blue       False   Bantamweight             3                    0.0   \n",
       "\n",
       "      B_current_win_streak  B_draw  B_avg_BODY_att  B_avg_BODY_landed  \\\n",
       "0                      1.0     0.0            4.00               3.00   \n",
       "1                      1.0     0.0            0.00               0.00   \n",
       "2                      0.0     0.0             NaN                NaN   \n",
       "3                      2.0     0.0            0.50               0.50   \n",
       "4                      0.0     0.0             NaN                NaN   \n",
       "...                    ...     ...             ...                ...   \n",
       "5057                   4.0     0.0            9.20               6.00   \n",
       "5058                   1.0     0.0           17.00              14.50   \n",
       "5059                   0.0     0.0             NaN                NaN   \n",
       "5060                   1.0     0.0            7.25               4.75   \n",
       "5061                   4.0     0.0           17.00              14.00   \n",
       "\n",
       "      B_avg_CLINCH_att  ...  R_Reach_cms  R_Weight_lbs  B_age  R_age  \\\n",
       "0                 9.00  ...          NaN         216.0    NaN   34.0   \n",
       "1                 0.00  ...          NaN         175.0   29.0   26.0   \n",
       "2                  NaN  ...          NaN         190.0    NaN   24.0   \n",
       "3                 0.00  ...          NaN         175.0   34.0   26.0   \n",
       "4                  NaN  ...          NaN         216.0   24.0   34.0   \n",
       "...                ...  ...          ...           ...    ...    ...   \n",
       "5057              0.20  ...       162.56         135.0   31.0   32.0   \n",
       "5058              2.50  ...       190.50         264.0   32.0   26.0   \n",
       "5059               NaN  ...       175.26         135.0   35.0   34.0   \n",
       "5060              1.75  ...       180.34         145.0   31.0   37.0   \n",
       "5061             13.75  ...       172.72         135.0   26.0   29.0   \n",
       "\n",
       "      location_elevation  end_method  end_round  attendance  R_home_elevation  \\\n",
       "0                1734.00         tko        NaN      7800.0              10.0   \n",
       "1                1734.00  submission        NaN      7800.0             270.0   \n",
       "2                1734.00  submission        NaN      7800.0             890.0   \n",
       "3                1734.00  submission        NaN      7800.0             270.0   \n",
       "4                1734.00         tko        NaN      7800.0              10.0   \n",
       "...                  ...         ...        ...         ...               ...   \n",
       "5057              182.02         tko        3.0     16083.0            3310.0   \n",
       "5058              182.02    decision        3.0     16083.0               NaN   \n",
       "5059              182.02          ko        2.0     16083.0            1950.0   \n",
       "5060              182.02          ko        1.0     16083.0              20.0   \n",
       "5061              182.02    decision        3.0     16083.0               NaN   \n",
       "\n",
       "      B_home_elevation  \n",
       "0                146.0  \n",
       "1              13730.0  \n",
       "2                  NaN  \n",
       "3                 10.0  \n",
       "4                 60.0  \n",
       "...                ...  \n",
       "5057               NaN  \n",
       "5058           22900.0  \n",
       "5059               NaN  \n",
       "5060             350.0  \n",
       "5061             900.0  \n",
       "\n",
       "[5062 rows x 146 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 6\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all of the feature columns\n",
    "numerical_cols = []\n",
    "categorical_cols = []\n",
    "\n",
    "for col, col_type in zip(ufc_data.dtypes.keys(), ufc_data.dtypes):\n",
    "    if col_type == 'float64' or col_type == 'int64':\n",
    "        numerical_cols.append(col)\n",
    "    else:\n",
    "        categorical_cols.append(col)\n",
    "        \n",
    "print(len(numerical_cols), len(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape (5062, 158), labels shape (5062,)\n"
     ]
    }
   ],
   "source": [
    "# Create the features and labels columns \n",
    "for col_name in categorical_cols:\n",
    "    null_count = ufc_data[ufc_data[col_name].isnull()].shape[0]\n",
    "    if (null_count > 0):\n",
    "        ufc_data = pd.get_dummies(ufc_data, columns=[col_name])\n",
    "    else:\n",
    "        col_data = ufc_data[col_name]\n",
    "        le = LabelEncoder().fit(col_data)\n",
    "        ufc_data[col_name] = le.transform(col_data)\n",
    "\n",
    "ufc_data = ufc_data.fillna(0)\n",
    "\n",
    "for col_name in ufc_data.columns:\n",
    "    null_count = ufc_data[ufc_data[col_name].isnull()].shape[0]\n",
    "    if null_count > 0:\n",
    "        print('{} has {} nulls'.format(col_name, ufc_data[ufc_data[col_name].isnull()].shape[0]))\n",
    "\n",
    "features = ufc_data.drop(columns=['Winner']).to_numpy()\n",
    "labels = ufc_data['Winner'].to_numpy()\n",
    "print('Features shape {}, labels shape {}'.format(features.shape, labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Builder and Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "def get_dnn(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Input Layer\n",
    "    model.add(Dense(params['first_neuron'], \n",
    "                    activation=params['activation'], \n",
    "                    input_dim=x_train.shape[1]))\n",
    "    \n",
    "    model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    # Hidden Layers\n",
    "    hidden_layers(model, params, 1)\n",
    "    \n",
    "    # Output Layers\n",
    "    model.add(Dense(1, activation=params['last_activation']))\n",
    "    \n",
    "    model.compile(\n",
    "        loss=params['losses'],\n",
    "        optimizer=params['optimizer'](lr=lr_normalizer(params['lr'], \n",
    "        params['optimizer'])), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "                  \n",
    "    history = model.fit(x_train, y_train,\n",
    "                       validation_data=[x_val, y_val],\n",
    "                       batch_size=params['batch_size'],\n",
    "                       epochs=params['epochs'],\n",
    "                       verbose=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    score = precision_recall_fscore_support(y_val, model.predict_classes(x_val), average='binary')\n",
    "    scores.append(score)\n",
    "\n",
    "    return history, model\n",
    "\n",
    "\n",
    "def run_model(features, labels):\n",
    "    # Define hyperparameters to use in Grid Search\n",
    "    dnn_params = {\n",
    "         'lr': [0.01, 0.1, 1],\n",
    "         'first_neuron': [64, 128],\n",
    "         'hidden_layers': [1, 2],\n",
    "         'batch_size': [64, 128],\n",
    "         'epochs': [10, 15, 25],\n",
    "         'dropout': [0, 0.1, 0.3],\n",
    "         'optimizer': [Adam],\n",
    "         'shapes':['brick', 'funnel'],\n",
    "         'losses': [binary_crossentropy],\n",
    "         'activation': [relu],\n",
    "         'last_activation': [sigmoid]\n",
    "    }\n",
    "\n",
    "    new_features, new_labels = shuffle(np.array(features), labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_features, new_labels, random_state=0, train_size=0.80)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    \n",
    "    # Create the Neural Network\n",
    "    dnn_model = ta.Scan(\n",
    "        x=scaler.transform(X_train),\n",
    "        y=y_train,\n",
    "        model=get_dnn,\n",
    "        params=dnn_params,\n",
    "        experiment_name='Winner_Predictor',\n",
    "        x_val=scaler.transform(X_test),\n",
    "        y_val=y_test,\n",
    "    )\n",
    "    \n",
    "    return dnn_model.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/432 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/432 [00:02<18:27,  2.57s/it]\u001b[A\n",
      "  0%|          | 2/432 [00:04<17:48,  2.48s/it]\u001b[A\n",
      "  1%|          | 3/432 [00:06<16:30,  2.31s/it]\u001b[A\n",
      "  1%|          | 4/432 [00:09<17:32,  2.46s/it]\u001b[A\n",
      "  1%|          | 5/432 [00:12<17:40,  2.48s/it]\u001b[A\n",
      "  1%|▏         | 6/432 [00:14<17:51,  2.52s/it]\u001b[A\n",
      "  2%|▏         | 7/432 [00:18<20:04,  2.83s/it]\u001b[A\n",
      "  2%|▏         | 8/432 [00:20<18:34,  2.63s/it]\u001b[A\n",
      "  2%|▏         | 9/432 [00:22<17:33,  2.49s/it]\u001b[A\n",
      "  2%|▏         | 10/432 [00:24<16:45,  2.38s/it]\u001b[A\n",
      "  3%|▎         | 11/432 [00:26<16:11,  2.31s/it]\u001b[A\n",
      "  3%|▎         | 12/432 [00:28<15:30,  2.22s/it]\u001b[A\n",
      "  3%|▎         | 13/432 [00:30<15:01,  2.15s/it]\u001b[A\n",
      "  3%|▎         | 14/432 [00:32<14:33,  2.09s/it]\u001b[A\n",
      "  3%|▎         | 15/432 [00:35<15:21,  2.21s/it]\u001b[A\n",
      "  4%|▎         | 16/432 [00:37<15:49,  2.28s/it]\u001b[A\n",
      "  4%|▍         | 17/432 [00:40<17:15,  2.50s/it]\u001b[A\n",
      "  4%|▍         | 18/432 [00:43<17:23,  2.52s/it]\u001b[A\n",
      "  4%|▍         | 19/432 [00:47<20:16,  2.94s/it]\u001b[A\n",
      "  5%|▍         | 20/432 [00:50<20:10,  2.94s/it]\u001b[A\n",
      "  5%|▍         | 21/432 [00:53<20:27,  2.99s/it]\u001b[A\n",
      "  5%|▌         | 22/432 [00:55<19:14,  2.82s/it]\u001b[A\n",
      "  5%|▌         | 23/432 [00:58<18:38,  2.74s/it]\u001b[A\n",
      "  6%|▌         | 24/432 [01:00<17:51,  2.63s/it]\u001b[A\n",
      "  6%|▌         | 25/432 [01:03<19:04,  2.81s/it]\u001b[A\n",
      "  6%|▌         | 26/432 [01:06<18:19,  2.71s/it]\u001b[A\n",
      "  6%|▋         | 27/432 [01:08<17:43,  2.63s/it]\u001b[A\n",
      "  6%|▋         | 28/432 [01:11<17:06,  2.54s/it]\u001b[A\n",
      "  7%|▋         | 29/432 [01:13<17:07,  2.55s/it]\u001b[A\n",
      "  7%|▋         | 30/432 [01:16<17:22,  2.59s/it]\u001b[A\n",
      "  7%|▋         | 31/432 [01:18<17:14,  2.58s/it]\u001b[A\n",
      "  7%|▋         | 32/432 [01:21<17:10,  2.58s/it]\u001b[A\n",
      "  8%|▊         | 33/432 [01:24<18:53,  2.84s/it]\u001b[A\n",
      "  8%|▊         | 34/432 [01:27<18:39,  2.81s/it]\u001b[A\n",
      "  8%|▊         | 35/432 [01:30<18:29,  2.79s/it]\u001b[A\n",
      "  8%|▊         | 36/432 [01:33<19:05,  2.89s/it]\u001b[A\n",
      "  9%|▊         | 37/432 [01:36<19:47,  3.01s/it]\u001b[A\n",
      "  9%|▉         | 38/432 [01:39<19:27,  2.96s/it]\u001b[A\n",
      "  9%|▉         | 39/432 [01:43<20:59,  3.21s/it]\u001b[A\n",
      "  9%|▉         | 40/432 [01:47<21:36,  3.31s/it]\u001b[A\n",
      "  9%|▉         | 41/432 [01:50<22:38,  3.47s/it]\u001b[A\n",
      " 10%|▉         | 42/432 [01:53<21:07,  3.25s/it]\u001b[A\n",
      " 10%|▉         | 43/432 [01:56<21:01,  3.24s/it]\u001b[A\n",
      " 10%|█         | 44/432 [01:59<20:10,  3.12s/it]\u001b[A\n",
      " 10%|█         | 45/432 [02:02<20:30,  3.18s/it]\u001b[A\n",
      " 11%|█         | 46/432 [02:05<19:59,  3.11s/it]\u001b[A\n",
      " 11%|█         | 47/432 [02:09<20:51,  3.25s/it]\u001b[A\n",
      " 11%|█         | 48/432 [02:12<21:15,  3.32s/it]\u001b[A\n",
      " 11%|█▏        | 49/432 [02:17<22:51,  3.58s/it]\u001b[A\n",
      " 12%|█▏        | 50/432 [02:20<22:55,  3.60s/it]\u001b[A\n",
      " 12%|█▏        | 51/432 [02:24<23:21,  3.68s/it]\u001b[A\n",
      " 12%|█▏        | 52/432 [02:28<22:39,  3.58s/it]\u001b[A\n",
      " 12%|█▏        | 53/432 [02:31<22:57,  3.64s/it]\u001b[A\n",
      " 12%|█▎        | 54/432 [02:35<23:49,  3.78s/it]\u001b[A\n",
      " 13%|█▎        | 55/432 [02:39<23:54,  3.80s/it]\u001b[A\n",
      " 13%|█▎        | 56/432 [02:44<24:43,  3.95s/it]\u001b[A\n",
      " 13%|█▎        | 57/432 [02:48<25:29,  4.08s/it]\u001b[A\n",
      " 13%|█▎        | 58/432 [02:52<26:02,  4.18s/it]\u001b[A\n",
      " 14%|█▎        | 59/432 [02:58<28:35,  4.60s/it]\u001b[A\n",
      " 14%|█▍        | 60/432 [03:04<31:02,  5.01s/it]\u001b[A\n",
      " 14%|█▍        | 61/432 [03:09<31:09,  5.04s/it]\u001b[A\n",
      " 14%|█▍        | 62/432 [03:13<28:41,  4.65s/it]\u001b[A\n",
      " 15%|█▍        | 63/432 [03:18<29:42,  4.83s/it]\u001b[A\n",
      " 15%|█▍        | 64/432 [03:22<28:37,  4.67s/it]\u001b[A\n",
      " 15%|█▌        | 65/432 [03:27<27:51,  4.56s/it]\u001b[A\n",
      " 15%|█▌        | 66/432 [03:30<25:38,  4.20s/it]\u001b[A\n",
      " 16%|█▌        | 67/432 [03:35<26:38,  4.38s/it]\u001b[A\n",
      " 16%|█▌        | 68/432 [03:40<27:16,  4.50s/it]\u001b[A\n",
      " 16%|█▌        | 69/432 [03:45<28:29,  4.71s/it]\u001b[A\n",
      " 16%|█▌        | 70/432 [03:50<28:50,  4.78s/it]\u001b[A\n",
      " 16%|█▋        | 71/432 [03:56<31:28,  5.23s/it]\u001b[A\n",
      " 17%|█▋        | 72/432 [04:04<36:13,  6.04s/it]\u001b[A\n",
      " 17%|█▋        | 73/432 [04:08<33:17,  5.56s/it]\u001b[A\n",
      " 17%|█▋        | 74/432 [04:11<28:30,  4.78s/it]\u001b[A\n",
      " 17%|█▋        | 75/432 [04:14<24:47,  4.17s/it]\u001b[A\n",
      " 18%|█▊        | 76/432 [04:17<22:03,  3.72s/it]\u001b[A\n",
      " 18%|█▊        | 77/432 [04:19<20:02,  3.39s/it]\u001b[A\n",
      " 18%|█▊        | 78/432 [04:22<18:12,  3.09s/it]\u001b[A\n",
      " 18%|█▊        | 79/432 [04:25<18:47,  3.19s/it]\u001b[A\n",
      " 19%|█▊        | 80/432 [04:28<18:37,  3.18s/it]\u001b[A\n",
      " 19%|█▉        | 81/432 [04:31<18:31,  3.17s/it]\u001b[A\n",
      " 19%|█▉        | 82/432 [04:35<18:55,  3.24s/it]\u001b[A\n",
      " 19%|█▉        | 83/432 [04:38<18:08,  3.12s/it]\u001b[A\n",
      " 19%|█▉        | 84/432 [04:40<17:10,  2.96s/it]\u001b[A\n",
      " 20%|█▉        | 85/432 [04:43<16:35,  2.87s/it]\u001b[A\n",
      " 20%|█▉        | 86/432 [04:46<16:08,  2.80s/it]\u001b[A\n",
      " 20%|██        | 87/432 [04:49<17:40,  3.07s/it]\u001b[A\n",
      " 20%|██        | 88/432 [04:52<16:57,  2.96s/it]\u001b[A\n",
      " 21%|██        | 89/432 [04:55<16:50,  2.95s/it]\u001b[A\n",
      " 21%|██        | 90/432 [04:57<16:10,  2.84s/it]\u001b[A\n",
      " 21%|██        | 91/432 [05:01<17:03,  3.00s/it]\u001b[A\n",
      " 21%|██▏       | 92/432 [05:04<17:16,  3.05s/it]\u001b[A\n",
      " 22%|██▏       | 93/432 [05:11<24:27,  4.33s/it]\u001b[A\n",
      " 22%|██▏       | 94/432 [05:21<33:26,  5.94s/it]\u001b[A\n",
      " 22%|██▏       | 95/432 [05:27<32:45,  5.83s/it]\u001b[A\n",
      " 22%|██▏       | 96/432 [05:34<34:39,  6.19s/it]\u001b[A\n",
      " 22%|██▏       | 97/432 [05:40<35:28,  6.35s/it]\u001b[A\n",
      " 23%|██▎       | 98/432 [05:44<31:13,  5.61s/it]\u001b[A\n",
      " 23%|██▎       | 99/432 [05:49<30:25,  5.48s/it]\u001b[A\n",
      " 23%|██▎       | 100/432 [05:53<27:32,  4.98s/it]\u001b[A\n",
      " 23%|██▎       | 101/432 [05:58<27:17,  4.95s/it]\u001b[A\n",
      " 24%|██▎       | 102/432 [06:03<27:07,  4.93s/it]\u001b[A\n",
      " 24%|██▍       | 103/432 [06:08<26:33,  4.84s/it]\u001b[A\n",
      " 24%|██▍       | 104/432 [06:11<24:44,  4.52s/it]\u001b[A\n",
      " 24%|██▍       | 105/432 [06:16<25:18,  4.64s/it]\u001b[A\n",
      " 25%|██▍       | 106/432 [06:22<26:08,  4.81s/it]\u001b[A\n",
      " 25%|██▍       | 107/432 [06:27<27:12,  5.02s/it]\u001b[A\n",
      " 25%|██▌       | 108/432 [06:32<27:22,  5.07s/it]\u001b[A\n",
      " 25%|██▌       | 109/432 [06:37<26:02,  4.84s/it]\u001b[A\n",
      " 25%|██▌       | 110/432 [06:41<25:12,  4.70s/it]\u001b[A\n",
      " 26%|██▌       | 111/432 [06:47<27:02,  5.05s/it]\u001b[A\n",
      " 26%|██▌       | 112/432 [06:51<26:03,  4.88s/it]\u001b[A\n",
      " 26%|██▌       | 113/432 [06:56<25:23,  4.78s/it]\u001b[A\n",
      " 26%|██▋       | 114/432 [07:00<23:42,  4.47s/it]\u001b[A\n",
      " 27%|██▋       | 115/432 [07:06<26:31,  5.02s/it]\u001b[A\n",
      " 27%|██▋       | 116/432 [07:11<26:13,  4.98s/it]\u001b[A\n",
      " 27%|██▋       | 117/432 [07:17<27:44,  5.28s/it]\u001b[A\n",
      " 27%|██▋       | 118/432 [07:22<27:28,  5.25s/it]\u001b[A\n",
      " 28%|██▊       | 119/432 [07:27<26:51,  5.15s/it]\u001b[A\n",
      " 28%|██▊       | 120/432 [07:31<25:36,  4.92s/it]\u001b[A\n",
      " 28%|██▊       | 121/432 [07:36<25:59,  5.01s/it]\u001b[A\n",
      " 28%|██▊       | 122/432 [07:41<25:47,  4.99s/it]\u001b[A\n",
      " 28%|██▊       | 123/432 [07:47<26:33,  5.16s/it]\u001b[A\n",
      " 29%|██▊       | 124/432 [07:56<32:16,  6.29s/it]\u001b[A\n",
      " 29%|██▉       | 125/432 [08:04<34:23,  6.72s/it]\u001b[A\n",
      " 29%|██▉       | 126/432 [08:10<34:07,  6.69s/it]\u001b[A\n",
      " 29%|██▉       | 127/432 [08:17<34:33,  6.80s/it]\u001b[A\n",
      " 30%|██▉       | 128/432 [08:23<32:36,  6.43s/it]\u001b[A\n",
      " 30%|██▉       | 129/432 [08:33<37:41,  7.46s/it]\u001b[A\n",
      " 30%|███       | 130/432 [08:42<39:38,  7.88s/it]\u001b[A\n",
      " 30%|███       | 131/432 [08:48<37:42,  7.52s/it]\u001b[A\n",
      " 31%|███       | 132/432 [08:54<34:45,  6.95s/it]\u001b[A\n",
      " 31%|███       | 133/432 [09:00<33:55,  6.81s/it]\u001b[A\n",
      " 31%|███       | 134/432 [09:06<31:30,  6.34s/it]\u001b[A\n",
      " 31%|███▏      | 135/432 [09:11<30:43,  6.21s/it]\u001b[A\n",
      " 31%|███▏      | 136/432 [09:18<31:04,  6.30s/it]\u001b[A\n",
      " 32%|███▏      | 137/432 [09:26<33:28,  6.81s/it]\u001b[A\n",
      " 32%|███▏      | 138/432 [09:35<36:34,  7.46s/it]\u001b[A\n",
      " 32%|███▏      | 139/432 [09:45<40:43,  8.34s/it]\u001b[A\n",
      " 32%|███▏      | 140/432 [09:51<37:01,  7.61s/it]\u001b[A\n",
      " 33%|███▎      | 141/432 [09:58<35:16,  7.27s/it]\u001b[A\n",
      " 33%|███▎      | 142/432 [10:04<33:24,  6.91s/it]\u001b[A\n",
      " 33%|███▎      | 143/432 [10:11<33:28,  6.95s/it]\u001b[A\n",
      " 33%|███▎      | 144/432 [10:18<33:07,  6.90s/it]\u001b[A\n",
      " 34%|███▎      | 145/432 [10:20<27:05,  5.66s/it]\u001b[A\n",
      " 34%|███▍      | 146/432 [10:23<22:29,  4.72s/it]\u001b[A\n",
      " 34%|███▍      | 147/432 [10:26<19:46,  4.16s/it]\u001b[A\n",
      " 34%|███▍      | 148/432 [10:28<16:54,  3.57s/it]\u001b[A\n",
      " 34%|███▍      | 149/432 [10:32<17:08,  3.63s/it]\u001b[A\n",
      " 35%|███▍      | 150/432 [10:35<16:54,  3.60s/it]\u001b[A\n",
      " 35%|███▍      | 151/432 [10:40<18:47,  4.01s/it]\u001b[A\n",
      " 35%|███▌      | 152/432 [10:44<18:06,  3.88s/it]\u001b[A\n",
      " 35%|███▌      | 153/432 [10:48<18:59,  4.08s/it]\u001b[A\n",
      " 36%|███▌      | 154/432 [10:53<19:12,  4.15s/it]\u001b[A\n",
      " 36%|███▌      | 155/432 [10:56<18:36,  4.03s/it]\u001b[A\n",
      " 36%|███▌      | 156/432 [11:00<17:18,  3.76s/it]\u001b[A\n",
      " 36%|███▋      | 157/432 [11:04<17:41,  3.86s/it]\u001b[A\n",
      " 37%|███▋      | 158/432 [11:06<16:08,  3.54s/it]\u001b[A\n",
      " 37%|███▋      | 159/432 [11:09<14:55,  3.28s/it]\u001b[A\n",
      " 37%|███▋      | 160/432 [11:12<14:16,  3.15s/it]\u001b[A\n",
      " 37%|███▋      | 161/432 [11:15<13:44,  3.04s/it]\u001b[A\n",
      " 38%|███▊      | 162/432 [11:17<13:15,  2.95s/it]\u001b[A\n",
      " 38%|███▊      | 163/432 [11:20<13:12,  2.95s/it]\u001b[A\n",
      " 38%|███▊      | 164/432 [11:24<14:08,  3.16s/it]\u001b[A\n",
      " 38%|███▊      | 165/432 [11:28<15:19,  3.44s/it]\u001b[A\n",
      " 38%|███▊      | 166/432 [11:30<13:37,  3.07s/it]\u001b[A\n",
      " 39%|███▊      | 167/432 [11:33<13:32,  3.07s/it]\u001b[A\n",
      " 39%|███▉      | 168/432 [11:36<12:48,  2.91s/it]\u001b[A\n",
      " 39%|███▉      | 169/432 [11:38<11:58,  2.73s/it]\u001b[A\n",
      " 39%|███▉      | 170/432 [11:40<11:05,  2.54s/it]\u001b[A\n",
      " 40%|███▉      | 171/432 [11:43<10:51,  2.50s/it]\u001b[A\n",
      " 40%|███▉      | 172/432 [11:45<10:47,  2.49s/it]\u001b[A\n",
      " 40%|████      | 173/432 [11:48<10:57,  2.54s/it]\u001b[A\n",
      " 40%|████      | 174/432 [11:50<10:36,  2.47s/it]\u001b[A\n",
      " 41%|████      | 175/432 [11:55<13:58,  3.26s/it]\u001b[A\n",
      " 41%|████      | 176/432 [11:59<14:00,  3.28s/it]\u001b[A\n",
      " 41%|████      | 177/432 [12:01<13:12,  3.11s/it]\u001b[A\n",
      " 41%|████      | 178/432 [12:06<14:52,  3.51s/it]\u001b[A\n",
      " 41%|████▏     | 179/432 [12:10<15:54,  3.77s/it]\u001b[A\n",
      " 42%|████▏     | 180/432 [12:13<14:33,  3.47s/it]\u001b[A\n",
      " 42%|████▏     | 181/432 [12:16<14:15,  3.41s/it]\u001b[A\n",
      " 42%|████▏     | 182/432 [12:19<13:15,  3.18s/it]\u001b[A\n",
      " 42%|████▏     | 183/432 [12:25<16:34,  4.00s/it]\u001b[A\n",
      " 43%|████▎     | 184/432 [12:27<14:28,  3.50s/it]\u001b[A\n",
      " 43%|████▎     | 185/432 [12:30<13:46,  3.35s/it]\u001b[A\n",
      " 43%|████▎     | 186/432 [12:33<13:07,  3.20s/it]\u001b[A\n",
      " 43%|████▎     | 187/432 [12:37<13:29,  3.30s/it]\u001b[A\n",
      " 44%|████▎     | 188/432 [12:39<12:22,  3.04s/it]\u001b[A\n",
      " 44%|████▍     | 189/432 [12:43<13:39,  3.37s/it]\u001b[A\n",
      " 44%|████▍     | 190/432 [12:47<13:57,  3.46s/it]\u001b[A\n",
      " 44%|████▍     | 191/432 [12:51<15:24,  3.84s/it]\u001b[A\n",
      " 44%|████▍     | 192/432 [12:55<14:55,  3.73s/it]\u001b[A\n",
      " 45%|████▍     | 193/432 [13:00<16:48,  4.22s/it]\u001b[A\n",
      " 45%|████▍     | 194/432 [13:06<18:25,  4.64s/it]\u001b[A\n",
      " 45%|████▌     | 195/432 [13:10<17:39,  4.47s/it]\u001b[A\n",
      " 45%|████▌     | 196/432 [13:15<18:07,  4.61s/it]\u001b[A\n",
      " 46%|████▌     | 197/432 [13:19<17:50,  4.55s/it]\u001b[A\n",
      " 46%|████▌     | 198/432 [13:24<17:32,  4.50s/it]\u001b[A\n",
      " 46%|████▌     | 199/432 [13:28<16:57,  4.37s/it]\u001b[A\n",
      " 46%|████▋     | 200/432 [13:32<17:10,  4.44s/it]\u001b[A\n",
      " 47%|████▋     | 201/432 [13:37<17:04,  4.44s/it]\u001b[A\n",
      " 47%|████▋     | 202/432 [13:41<16:30,  4.30s/it]\u001b[A\n",
      " 47%|████▋     | 203/432 [13:46<17:45,  4.65s/it]\u001b[A\n",
      " 47%|████▋     | 204/432 [13:51<17:42,  4.66s/it]\u001b[A\n",
      " 47%|████▋     | 205/432 [13:55<17:23,  4.60s/it]\u001b[A\n",
      " 48%|████▊     | 206/432 [13:59<16:22,  4.35s/it]\u001b[A\n",
      " 48%|████▊     | 207/432 [14:03<15:44,  4.20s/it]\u001b[A\n",
      " 48%|████▊     | 208/432 [14:07<14:52,  3.98s/it]\u001b[A\n",
      " 48%|████▊     | 209/432 [14:10<14:41,  3.95s/it]\u001b[A\n",
      " 49%|████▊     | 210/432 [14:13<13:35,  3.67s/it]\u001b[A\n",
      " 49%|████▉     | 211/432 [14:17<13:56,  3.79s/it]\u001b[A\n",
      " 49%|████▉     | 212/432 [14:21<14:07,  3.85s/it]\u001b[A\n",
      " 49%|████▉     | 213/432 [14:25<14:08,  3.87s/it]\u001b[A\n",
      " 50%|████▉     | 214/432 [14:29<14:08,  3.89s/it]\u001b[A\n",
      " 50%|████▉     | 215/432 [14:35<16:30,  4.56s/it]\u001b[A\n",
      " 50%|█████     | 216/432 [14:40<16:25,  4.56s/it]\u001b[A\n",
      " 50%|█████     | 217/432 [14:41<12:41,  3.54s/it]\u001b[A\n",
      " 50%|█████     | 218/432 [14:42<10:04,  2.82s/it]\u001b[A\n",
      " 51%|█████     | 219/432 [14:44<08:54,  2.51s/it]\u001b[A\n",
      " 51%|█████     | 220/432 [14:45<07:25,  2.10s/it]\u001b[A\n",
      " 51%|█████     | 221/432 [14:47<06:34,  1.87s/it]\u001b[A\n",
      " 51%|█████▏    | 222/432 [14:48<05:52,  1.68s/it]\u001b[A\n",
      " 52%|█████▏    | 223/432 [14:49<05:35,  1.61s/it]\u001b[A\n",
      " 52%|█████▏    | 224/432 [14:51<05:11,  1.50s/it]\u001b[A\n",
      " 52%|█████▏    | 225/432 [14:52<04:52,  1.41s/it]\u001b[A\n",
      " 52%|█████▏    | 226/432 [14:53<04:44,  1.38s/it]\u001b[A\n",
      " 53%|█████▎    | 227/432 [14:54<04:33,  1.33s/it]\u001b[A\n",
      " 53%|█████▎    | 228/432 [14:55<04:23,  1.29s/it]\u001b[A\n",
      " 53%|█████▎    | 229/432 [14:57<04:18,  1.27s/it]\u001b[A\n",
      " 53%|█████▎    | 230/432 [14:58<04:21,  1.29s/it]\u001b[A\n",
      " 53%|█████▎    | 231/432 [15:00<05:19,  1.59s/it]\u001b[A\n",
      " 54%|█████▎    | 232/432 [15:02<05:01,  1.51s/it]\u001b[A\n",
      " 54%|█████▍    | 233/432 [15:03<04:46,  1.44s/it]\u001b[A\n",
      " 54%|█████▍    | 234/432 [15:05<04:55,  1.49s/it]\u001b[A\n",
      " 54%|█████▍    | 235/432 [15:06<05:19,  1.62s/it]\u001b[A\n",
      " 55%|█████▍    | 236/432 [15:08<04:56,  1.51s/it]\u001b[A\n",
      " 55%|█████▍    | 237/432 [15:10<05:52,  1.81s/it]\u001b[A\n",
      " 55%|█████▌    | 238/432 [15:12<05:33,  1.72s/it]\u001b[A\n",
      " 55%|█████▌    | 239/432 [15:14<05:35,  1.74s/it]\u001b[A\n",
      " 56%|█████▌    | 240/432 [15:16<06:01,  1.88s/it]\u001b[A\n",
      " 56%|█████▌    | 241/432 [15:18<06:20,  1.99s/it]\u001b[A\n",
      " 56%|█████▌    | 242/432 [15:21<07:29,  2.37s/it]\u001b[A\n",
      " 56%|█████▋    | 243/432 [15:23<07:16,  2.31s/it]\u001b[A\n",
      " 56%|█████▋    | 244/432 [15:25<06:09,  1.97s/it]\u001b[A\n",
      " 57%|█████▋    | 245/432 [15:26<05:42,  1.83s/it]\u001b[A\n",
      " 57%|█████▋    | 246/432 [15:27<05:03,  1.63s/it]\u001b[A\n",
      " 57%|█████▋    | 247/432 [15:29<04:46,  1.55s/it]\u001b[A\n",
      " 57%|█████▋    | 248/432 [15:31<05:23,  1.76s/it]\u001b[A\n",
      " 58%|█████▊    | 249/432 [15:34<06:23,  2.10s/it]\u001b[A\n",
      " 58%|█████▊    | 250/432 [15:36<06:49,  2.25s/it]\u001b[A\n",
      " 58%|█████▊    | 251/432 [15:40<07:52,  2.61s/it]\u001b[A\n",
      " 58%|█████▊    | 252/432 [15:42<07:28,  2.49s/it]\u001b[A\n",
      " 59%|█████▊    | 253/432 [15:44<06:58,  2.34s/it]\u001b[A\n",
      " 59%|█████▉    | 254/432 [15:45<06:10,  2.08s/it]\u001b[A\n",
      " 59%|█████▉    | 255/432 [15:47<05:55,  2.01s/it]\u001b[A\n",
      " 59%|█████▉    | 256/432 [15:49<05:52,  2.00s/it]\u001b[A\n",
      " 59%|█████▉    | 257/432 [15:53<07:17,  2.50s/it]\u001b[A\n",
      " 60%|█████▉    | 258/432 [15:56<07:26,  2.56s/it]\u001b[A\n",
      " 60%|█████▉    | 259/432 [15:58<06:56,  2.41s/it]\u001b[A\n",
      " 60%|██████    | 260/432 [15:59<06:13,  2.17s/it]\u001b[A\n",
      " 60%|██████    | 261/432 [16:01<05:56,  2.09s/it]\u001b[A\n",
      " 61%|██████    | 262/432 [16:03<05:34,  1.96s/it]\u001b[A\n",
      " 61%|██████    | 263/432 [16:05<05:33,  1.97s/it]\u001b[A\n",
      " 61%|██████    | 264/432 [16:07<05:44,  2.05s/it]\u001b[A\n",
      " 61%|██████▏   | 265/432 [16:09<05:35,  2.01s/it]\u001b[A\n",
      " 62%|██████▏   | 266/432 [16:11<05:32,  2.00s/it]\u001b[A\n",
      " 62%|██████▏   | 267/432 [16:13<05:30,  2.01s/it]\u001b[A\n",
      " 62%|██████▏   | 268/432 [16:15<05:25,  1.99s/it]\u001b[A\n",
      " 62%|██████▏   | 269/432 [16:17<05:24,  1.99s/it]\u001b[A\n",
      " 62%|██████▎   | 270/432 [16:18<05:00,  1.85s/it]\u001b[A\n",
      " 63%|██████▎   | 271/432 [16:20<04:55,  1.84s/it]\u001b[A\n",
      " 63%|██████▎   | 272/432 [16:22<04:48,  1.81s/it]\u001b[A\n",
      " 63%|██████▎   | 273/432 [16:25<05:32,  2.09s/it]\u001b[A\n",
      " 63%|██████▎   | 274/432 [16:27<05:27,  2.07s/it]\u001b[A\n",
      " 64%|██████▎   | 275/432 [16:29<05:28,  2.09s/it]\u001b[A\n",
      " 64%|██████▍   | 276/432 [16:31<05:14,  2.02s/it]\u001b[A\n",
      " 64%|██████▍   | 277/432 [16:33<05:16,  2.04s/it]\u001b[A\n",
      " 64%|██████▍   | 278/432 [16:35<05:03,  1.97s/it]\u001b[A\n",
      " 65%|██████▍   | 279/432 [16:37<05:05,  2.00s/it]\u001b[A\n",
      " 65%|██████▍   | 280/432 [16:39<04:57,  1.96s/it]\u001b[A\n",
      " 65%|██████▌   | 281/432 [16:41<04:59,  1.99s/it]\u001b[A\n",
      " 65%|██████▌   | 282/432 [16:43<04:53,  1.96s/it]\u001b[A\n",
      " 66%|██████▌   | 283/432 [16:45<05:21,  2.16s/it]\u001b[A\n",
      " 66%|██████▌   | 284/432 [16:48<05:31,  2.24s/it]\u001b[A\n",
      " 66%|██████▌   | 285/432 [16:51<06:19,  2.58s/it]\u001b[A\n",
      " 66%|██████▌   | 286/432 [16:53<05:58,  2.45s/it]\u001b[A\n",
      " 66%|██████▋   | 287/432 [16:56<05:59,  2.48s/it]\u001b[A\n",
      " 67%|██████▋   | 288/432 [16:58<05:40,  2.36s/it]\u001b[A\n",
      " 67%|██████▋   | 289/432 [16:59<04:54,  2.06s/it]\u001b[A\n",
      " 67%|██████▋   | 290/432 [17:00<04:22,  1.85s/it]\u001b[A\n",
      " 67%|██████▋   | 291/432 [17:02<03:59,  1.70s/it]\u001b[A\n",
      " 68%|██████▊   | 292/432 [17:03<03:46,  1.62s/it]\u001b[A\n",
      " 68%|██████▊   | 293/432 [17:05<03:31,  1.53s/it]\u001b[A\n",
      " 68%|██████▊   | 294/432 [17:06<03:36,  1.57s/it]\u001b[A\n",
      " 68%|██████▊   | 295/432 [17:08<03:40,  1.61s/it]\u001b[A\n",
      " 69%|██████▊   | 296/432 [17:10<03:39,  1.61s/it]\u001b[A\n",
      " 69%|██████▉   | 297/432 [17:12<04:10,  1.86s/it]\u001b[A\n",
      " 69%|██████▉   | 298/432 [17:17<06:13,  2.79s/it]\u001b[A\n",
      " 69%|██████▉   | 299/432 [17:20<06:12,  2.80s/it]\u001b[A\n",
      " 69%|██████▉   | 300/432 [17:22<05:41,  2.59s/it]\u001b[A\n",
      " 70%|██████▉   | 301/432 [17:24<05:12,  2.38s/it]\u001b[A\n",
      " 70%|██████▉   | 302/432 [17:27<05:42,  2.64s/it]\u001b[A\n",
      " 70%|███████   | 303/432 [17:31<06:41,  3.12s/it]\u001b[A\n",
      " 70%|███████   | 304/432 [17:33<05:37,  2.64s/it]\u001b[A\n",
      " 71%|███████   | 305/432 [17:35<05:29,  2.60s/it]\u001b[A\n",
      " 71%|███████   | 306/432 [17:37<04:42,  2.24s/it]\u001b[A\n",
      " 71%|███████   | 307/432 [17:39<04:41,  2.25s/it]\u001b[A\n",
      " 71%|███████▏  | 308/432 [17:41<04:28,  2.17s/it]\u001b[A\n",
      " 72%|███████▏  | 309/432 [17:43<04:21,  2.12s/it]\u001b[A\n",
      " 72%|███████▏  | 310/432 [17:45<04:21,  2.14s/it]\u001b[A\n",
      " 72%|███████▏  | 311/432 [17:47<04:13,  2.09s/it]\u001b[A\n",
      " 72%|███████▏  | 312/432 [17:49<04:09,  2.08s/it]\u001b[A\n",
      " 72%|███████▏  | 313/432 [17:51<04:16,  2.16s/it]\u001b[A\n",
      " 73%|███████▎  | 314/432 [17:53<04:00,  2.04s/it]\u001b[A\n",
      " 73%|███████▎  | 315/432 [17:55<03:44,  1.92s/it]\u001b[A\n",
      " 73%|███████▎  | 316/432 [17:57<03:37,  1.88s/it]\u001b[A\n",
      " 73%|███████▎  | 317/432 [17:59<03:37,  1.89s/it]\u001b[A\n",
      " 74%|███████▎  | 318/432 [18:01<04:04,  2.15s/it]\u001b[A\n",
      " 74%|███████▍  | 319/432 [18:04<04:18,  2.29s/it]\u001b[A\n",
      " 74%|███████▍  | 320/432 [18:06<04:08,  2.22s/it]\u001b[A\n",
      " 74%|███████▍  | 321/432 [18:08<04:08,  2.24s/it]\u001b[A\n",
      " 75%|███████▍  | 322/432 [18:10<04:03,  2.22s/it]\u001b[A\n",
      " 75%|███████▍  | 323/432 [18:13<04:13,  2.33s/it]\u001b[A\n",
      " 75%|███████▌  | 324/432 [18:15<04:08,  2.30s/it]\u001b[A\n",
      " 75%|███████▌  | 325/432 [18:18<04:14,  2.38s/it]\u001b[A\n",
      " 75%|███████▌  | 326/432 [18:21<04:33,  2.58s/it]\u001b[A\n",
      " 76%|███████▌  | 327/432 [18:23<04:27,  2.55s/it]\u001b[A\n",
      " 76%|███████▌  | 328/432 [18:25<03:56,  2.27s/it]\u001b[A\n",
      " 76%|███████▌  | 329/432 [18:27<03:45,  2.19s/it]\u001b[A\n",
      " 76%|███████▋  | 330/432 [18:29<03:23,  2.00s/it]\u001b[A\n",
      " 77%|███████▋  | 331/432 [18:31<03:46,  2.24s/it]\u001b[A\n",
      " 77%|███████▋  | 332/432 [18:34<03:49,  2.30s/it]\u001b[A\n",
      " 77%|███████▋  | 333/432 [18:36<03:49,  2.31s/it]\u001b[A\n",
      " 77%|███████▋  | 334/432 [18:38<03:35,  2.20s/it]\u001b[A\n",
      " 78%|███████▊  | 335/432 [18:40<03:32,  2.19s/it]\u001b[A\n",
      " 78%|███████▊  | 336/432 [18:42<03:26,  2.15s/it]\u001b[A\n",
      " 78%|███████▊  | 337/432 [18:45<03:29,  2.21s/it]\u001b[A\n",
      " 78%|███████▊  | 338/432 [18:47<03:20,  2.13s/it]\u001b[A\n",
      " 78%|███████▊  | 339/432 [18:49<03:37,  2.34s/it]\u001b[A\n",
      " 79%|███████▊  | 340/432 [18:52<03:49,  2.49s/it]\u001b[A\n",
      " 79%|███████▉  | 341/432 [18:56<04:29,  2.96s/it]\u001b[A\n",
      " 79%|███████▉  | 342/432 [19:00<04:37,  3.09s/it]\u001b[A\n",
      " 79%|███████▉  | 343/432 [19:03<04:27,  3.01s/it]\u001b[A\n",
      " 80%|███████▉  | 344/432 [19:06<04:30,  3.07s/it]\u001b[A\n",
      " 80%|███████▉  | 345/432 [19:09<04:40,  3.22s/it]\u001b[A\n",
      " 80%|████████  | 346/432 [19:12<04:25,  3.09s/it]\u001b[A\n",
      " 80%|████████  | 347/432 [19:15<04:23,  3.10s/it]\u001b[A\n",
      " 81%|████████  | 348/432 [19:17<03:59,  2.85s/it]\u001b[A\n",
      " 81%|████████  | 349/432 [19:20<03:45,  2.72s/it]\u001b[A\n",
      " 81%|████████  | 350/432 [19:22<03:26,  2.52s/it]\u001b[A\n",
      " 81%|████████▏ | 351/432 [19:25<03:30,  2.60s/it]\u001b[A\n",
      " 81%|████████▏ | 352/432 [19:28<03:43,  2.80s/it]\u001b[A\n",
      " 82%|████████▏ | 353/432 [19:31<03:41,  2.81s/it]\u001b[A\n",
      " 82%|████████▏ | 354/432 [19:33<03:30,  2.70s/it]\u001b[A\n",
      " 82%|████████▏ | 355/432 [19:38<04:17,  3.35s/it]\u001b[A\n",
      " 82%|████████▏ | 356/432 [19:41<04:12,  3.32s/it]\u001b[A\n",
      " 83%|████████▎ | 357/432 [19:45<04:17,  3.44s/it]\u001b[A\n",
      " 83%|████████▎ | 358/432 [19:50<04:41,  3.80s/it]\u001b[A\n",
      " 83%|████████▎ | 359/432 [19:55<05:16,  4.34s/it]\u001b[A\n",
      " 83%|████████▎ | 360/432 [20:00<05:28,  4.56s/it]\u001b[A\n",
      " 84%|████████▎ | 361/432 [20:03<04:38,  3.92s/it]\u001b[A\n",
      " 84%|████████▍ | 362/432 [20:06<04:09,  3.57s/it]\u001b[A\n",
      " 84%|████████▍ | 363/432 [20:08<03:41,  3.20s/it]\u001b[A\n",
      " 84%|████████▍ | 364/432 [20:09<02:59,  2.64s/it]\u001b[A\n",
      " 84%|████████▍ | 365/432 [20:11<02:35,  2.32s/it]\u001b[A\n",
      " 85%|████████▍ | 366/432 [20:12<02:14,  2.04s/it]\u001b[A\n",
      " 85%|████████▍ | 367/432 [20:14<02:08,  1.98s/it]\u001b[A\n",
      " 85%|████████▌ | 368/432 [20:16<01:57,  1.83s/it]\u001b[A\n",
      " 85%|████████▌ | 369/432 [20:18<01:57,  1.87s/it]\u001b[A\n",
      " 86%|████████▌ | 370/432 [20:19<01:53,  1.83s/it]\u001b[A\n",
      " 86%|████████▌ | 371/432 [20:21<01:45,  1.73s/it]\u001b[A\n",
      " 86%|████████▌ | 372/432 [20:22<01:39,  1.66s/it]\u001b[A\n",
      " 86%|████████▋ | 373/432 [20:24<01:33,  1.59s/it]\u001b[A\n",
      " 87%|████████▋ | 374/432 [20:25<01:26,  1.50s/it]\u001b[A\n",
      " 87%|████████▋ | 375/432 [20:26<01:23,  1.47s/it]\u001b[A\n",
      " 87%|████████▋ | 376/432 [20:28<01:19,  1.42s/it]\u001b[A\n",
      " 87%|████████▋ | 377/432 [20:29<01:23,  1.53s/it]\u001b[A\n",
      " 88%|████████▊ | 378/432 [20:31<01:22,  1.53s/it]\u001b[A\n",
      " 88%|████████▊ | 379/432 [20:34<01:49,  2.06s/it]\u001b[A\n",
      " 88%|████████▊ | 380/432 [20:37<01:55,  2.21s/it]\u001b[A\n",
      " 88%|████████▊ | 381/432 [20:39<01:52,  2.20s/it]\u001b[A\n",
      " 88%|████████▊ | 382/432 [20:41<01:47,  2.15s/it]\u001b[A\n",
      " 89%|████████▊ | 383/432 [20:43<01:44,  2.12s/it]\u001b[A\n",
      " 89%|████████▉ | 384/432 [20:45<01:41,  2.11s/it]\u001b[A\n",
      " 89%|████████▉ | 385/432 [20:47<01:36,  2.05s/it]\u001b[A\n",
      " 89%|████████▉ | 386/432 [20:50<01:41,  2.20s/it]\u001b[A\n",
      " 90%|████████▉ | 387/432 [20:52<01:47,  2.39s/it]\u001b[A\n",
      " 90%|████████▉ | 388/432 [20:55<01:46,  2.42s/it]\u001b[A\n",
      " 90%|█████████ | 389/432 [20:57<01:40,  2.33s/it]\u001b[A\n",
      " 90%|█████████ | 390/432 [20:59<01:33,  2.23s/it]\u001b[A\n",
      " 91%|█████████ | 391/432 [21:01<01:31,  2.23s/it]\u001b[A\n",
      " 91%|█████████ | 392/432 [21:03<01:28,  2.20s/it]\u001b[A\n",
      " 91%|█████████ | 393/432 [21:06<01:27,  2.26s/it]\u001b[A\n",
      " 91%|█████████ | 394/432 [21:08<01:25,  2.25s/it]\u001b[A\n",
      " 91%|█████████▏| 395/432 [21:11<01:26,  2.34s/it]\u001b[A\n",
      " 92%|█████████▏| 396/432 [21:13<01:25,  2.37s/it]\u001b[A\n",
      " 92%|█████████▏| 397/432 [21:16<01:30,  2.59s/it]\u001b[A\n",
      " 92%|█████████▏| 398/432 [21:18<01:20,  2.37s/it]\u001b[A\n",
      " 92%|█████████▏| 399/432 [21:21<01:20,  2.44s/it]\u001b[A\n",
      " 93%|█████████▎| 400/432 [21:22<01:12,  2.27s/it]\u001b[A\n",
      " 93%|█████████▎| 401/432 [21:25<01:11,  2.30s/it]\u001b[A\n",
      " 93%|█████████▎| 402/432 [21:27<01:06,  2.20s/it]\u001b[A\n",
      " 93%|█████████▎| 403/432 [21:31<01:18,  2.71s/it]\u001b[A\n",
      " 94%|█████████▎| 404/432 [21:33<01:13,  2.61s/it]\u001b[A\n",
      " 94%|█████████▍| 405/432 [21:36<01:12,  2.70s/it]\u001b[A\n",
      " 94%|█████████▍| 406/432 [21:38<01:08,  2.64s/it]\u001b[A\n",
      " 94%|█████████▍| 407/432 [21:41<01:07,  2.71s/it]\u001b[A\n",
      " 94%|█████████▍| 408/432 [21:44<01:04,  2.71s/it]\u001b[A\n",
      " 95%|█████████▍| 409/432 [21:47<01:02,  2.73s/it]\u001b[A\n",
      " 95%|█████████▍| 410/432 [21:49<00:58,  2.68s/it]\u001b[A\n",
      " 95%|█████████▌| 411/432 [21:52<00:56,  2.68s/it]\u001b[A\n",
      " 95%|█████████▌| 412/432 [21:55<00:52,  2.63s/it]\u001b[A\n",
      " 96%|█████████▌| 413/432 [21:57<00:49,  2.61s/it]\u001b[A\n",
      " 96%|█████████▌| 414/432 [22:00<00:46,  2.59s/it]\u001b[A\n",
      " 96%|█████████▌| 415/432 [22:03<00:46,  2.73s/it]\u001b[A\n",
      " 96%|█████████▋| 416/432 [22:06<00:47,  3.00s/it]\u001b[A\n",
      " 97%|█████████▋| 417/432 [22:09<00:44,  2.98s/it]\u001b[A\n",
      " 97%|█████████▋| 418/432 [22:12<00:40,  2.92s/it]\u001b[A\n",
      " 97%|█████████▋| 419/432 [22:15<00:38,  2.96s/it]\u001b[A\n",
      " 97%|█████████▋| 420/432 [22:18<00:34,  2.89s/it]\u001b[A\n",
      " 97%|█████████▋| 421/432 [22:21<00:31,  2.83s/it]\u001b[A\n",
      " 98%|█████████▊| 422/432 [22:23<00:27,  2.77s/it]\u001b[A\n",
      " 98%|█████████▊| 423/432 [22:26<00:25,  2.82s/it]\u001b[A\n",
      " 98%|█████████▊| 424/432 [22:29<00:22,  2.82s/it]\u001b[A\n",
      " 98%|█████████▊| 425/432 [22:32<00:20,  2.87s/it]\u001b[A\n",
      " 99%|█████████▊| 426/432 [22:35<00:17,  2.89s/it]\u001b[A\n",
      " 99%|█████████▉| 427/432 [22:39<00:16,  3.30s/it]\u001b[A\n",
      " 99%|█████████▉| 428/432 [22:43<00:13,  3.38s/it]\u001b[A\n",
      " 99%|█████████▉| 429/432 [22:47<00:11,  3.69s/it]\u001b[A\n",
      "100%|█████████▉| 430/432 [22:51<00:07,  3.72s/it]\u001b[A\n",
      "100%|█████████▉| 431/432 [22:56<00:04,  4.16s/it]\u001b[A\n",
      "100%|██████████| 432/432 [23:00<00:00,  3.20s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "results_df = run_model(features, labels)\n",
    "dnn_cols = list(results_df.columns)\n",
    "score_cols = ['precision', 'recall', 'fbeta_score', 'support']\n",
    "\n",
    "new_df_data = []\n",
    "\n",
    "for index, row_data in results_df.iterrows():\n",
    "    new_row = dict()\n",
    "    \n",
    "    for col in dnn_cols:\n",
    "        new_row[col] = row_data[col]\n",
    "    \n",
    "    for score_index, col in enumerate(score_cols):\n",
    "        new_row[col] = scores[index][score_index]\n",
    "        \n",
    "    new_df_data.append(new_row)\n",
    "\n",
    "combined_results_df = pd.DataFrame(new_df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>lr</th>\n",
       "      <th>shapes</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>15</td>\n",
       "      <td>0.553277</td>\n",
       "      <td>0.720632</td>\n",
       "      <td>0.574968</td>\n",
       "      <td>0.680662</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.738623</td>\n",
       "      <td>0.914740</td>\n",
       "      <td>0.817301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>25</td>\n",
       "      <td>0.529100</td>\n",
       "      <td>0.716683</td>\n",
       "      <td>0.481343</td>\n",
       "      <td>0.757718</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.748466</td>\n",
       "      <td>0.881503</td>\n",
       "      <td>0.809555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>25</td>\n",
       "      <td>0.542733</td>\n",
       "      <td>0.715696</td>\n",
       "      <td>0.553883</td>\n",
       "      <td>0.705359</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.927746</td>\n",
       "      <td>0.816794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>0.544620</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>0.538246</td>\n",
       "      <td>0.714003</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.725140</td>\n",
       "      <td>0.937861</td>\n",
       "      <td>0.817895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>15</td>\n",
       "      <td>0.531167</td>\n",
       "      <td>0.713722</td>\n",
       "      <td>0.554812</td>\n",
       "      <td>0.716720</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>funnel</td>\n",
       "      <td>0.725843</td>\n",
       "      <td>0.933526</td>\n",
       "      <td>0.816688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_accuracy      loss  accuracy  batch_size  \\\n",
       "188            15  0.553277      0.720632  0.574968  0.680662          64   \n",
       "134            25  0.529100      0.716683  0.481343  0.757718          64   \n",
       "422            25  0.542733      0.715696  0.553883  0.705359         128   \n",
       "92             10  0.544620      0.714709  0.538246  0.714003          64   \n",
       "395            15  0.531167      0.713722  0.554812  0.716720         128   \n",
       "\n",
       "     dropout  epochs  first_neuron  hidden_layers   lr  shapes  precision  \\\n",
       "188      0.3      15           128              2  0.1   brick   0.738623   \n",
       "134      0.1      25           128              1  0.1   brick   0.748466   \n",
       "422      0.3      25           128              1  0.1   brick   0.729545   \n",
       "92       0.1      10           128              2  0.1   brick   0.725140   \n",
       "395      0.3      15            64              2  1.0  funnel   0.725843   \n",
       "\n",
       "       recall  fbeta_score  \n",
       "188  0.914740     0.817301  \n",
       "134  0.881503     0.809555  \n",
       "422  0.927746     0.816794  \n",
       "92   0.937861     0.817895  \n",
       "395  0.933526     0.816688  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_val_accuracy = combined_results_df.sort_values(by=['val_accuracy'], ascending=False).head(5)\n",
    "top_10_val_accuracy.drop(columns=['activation', 'last_activation', 'optimizer', 'support', 'losses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>lr</th>\n",
       "      <th>shapes</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>25</td>\n",
       "      <td>1.738132</td>\n",
       "      <td>0.691017</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.991603</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.751660</td>\n",
       "      <td>0.817919</td>\n",
       "      <td>0.783391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>1.217835</td>\n",
       "      <td>0.688055</td>\n",
       "      <td>0.042980</td>\n",
       "      <td>0.989627</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.748021</td>\n",
       "      <td>0.819364</td>\n",
       "      <td>0.782069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "      <td>1.978865</td>\n",
       "      <td>0.667325</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.987651</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.751773</td>\n",
       "      <td>0.765896</td>\n",
       "      <td>0.758769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>25</td>\n",
       "      <td>1.092236</td>\n",
       "      <td>0.692991</td>\n",
       "      <td>0.070343</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.750329</td>\n",
       "      <td>0.825145</td>\n",
       "      <td>0.785960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>1.753901</td>\n",
       "      <td>0.684107</td>\n",
       "      <td>0.043594</td>\n",
       "      <td>0.983947</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>brick</td>\n",
       "      <td>0.739691</td>\n",
       "      <td>0.829480</td>\n",
       "      <td>0.782016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_accuracy      loss  accuracy  batch_size  \\\n",
       "286            25  1.738132      0.691017  0.022021  0.991603         128   \n",
       "64             25  1.217835      0.688055  0.042980  0.989627          64   \n",
       "70             25  1.978865      0.667325  0.028984  0.987651          64   \n",
       "280            25  1.092236      0.692991  0.070343  0.985675         128   \n",
       "58             25  1.753901      0.684107  0.043594  0.983947          64   \n",
       "\n",
       "     dropout  epochs  first_neuron  hidden_layers   lr shapes  precision  \\\n",
       "286      0.0      25           128              2  1.0  brick   0.751660   \n",
       "64       0.0      25           128              1  1.0  brick   0.748021   \n",
       "70       0.0      25           128              2  1.0  brick   0.751773   \n",
       "280      0.0      25           128              1  1.0  brick   0.750329   \n",
       "58       0.0      25            64              2  1.0  brick   0.739691   \n",
       "\n",
       "       recall  fbeta_score  \n",
       "286  0.817919     0.783391  \n",
       "64   0.819364     0.782069  \n",
       "70   0.765896     0.758769  \n",
       "280  0.825145     0.785960  \n",
       "58   0.829480     0.782016  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_val = combined_results_df.sort_values(by=['accuracy'], ascending=False).head(5)\n",
    "top_10_val.drop(columns=['activation', 'last_activation', 'optimizer', 'support', 'losses'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
